{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc6a885-3727-47a3-8366-c189e76cd5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this NoteBook is for update detection for the Hotel Details Dataset using Jupyter Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b148418c-fb74-4689-9d75-a2e5736c5fff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34a2624-e0f6-4e22-af50-dcb67430c3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa13f17-bb80-492a-97e0-824868c11fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def load_data(filepath, input_template_path=None):\n",
    "#     try:\n",
    "#         # Try loading the existing data\n",
    "#         df = pd.read_csv(filepath, parse_dates=['last_updated'])\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"No file found at {filepath}. Initializing an empty DataFrame based on the template path.\")\n",
    "#         # If no file is found and a template path is provided, create a DataFrame with the same structure\n",
    "#         if input_template_path:\n",
    "#             # Load only headers from the input template\n",
    "#             temp_df = pd.read_csv(input_template_path, nrows=0)\n",
    "#             columns = temp_df.columns.tolist()  # Get all column names from the input dataset\n",
    "#         else:\n",
    "#             # Fallback to a default set of columns if no input template path is provided\n",
    "#             columns = ['hotel_id', 'name', 'location', 'description']  # Default columns if no template is available\n",
    "\n",
    "#         # Initialize an empty DataFrame with the structure derived from the input dataset\n",
    "#         df = pd.DataFrame(columns=columns)\n",
    "#         df['last_updated'] = pd.to_datetime(datetime.now())  # Ensure this column is added and set to now\n",
    "#         df['data_hash'] = pd.NA  # Initialize data_hash as missing\n",
    "        \n",
    "#     return df\n",
    "\n",
    "def load_data(filepath, input_template_path=None):\n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        if 'last_updated' in df.columns:\n",
    "            df['last_updated'] = pd.to_datetime(df['last_updated'])\n",
    "        else:\n",
    "            df['last_updated'] = pd.to_datetime(datetime.now())\n",
    "    except FileNotFoundError:\n",
    "        print(f\"No file found at {filepath}. Initializing based on the input template.\")\n",
    "        if input_template_path:\n",
    "            temp_df = pd.read_csv(input_template_path, nrows=0)\n",
    "            df = pd.DataFrame(columns=temp_df.columns)\n",
    "        else:\n",
    "            df = pd.DataFrame(columns=['hotel_id', 'name', 'location', 'description'])\n",
    "        df['last_updated'] = pd.to_datetime(datetime.now())\n",
    "        df['data_hash'] = pd.NA\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689eee81-04e1-4bfc-a0fb-6ebda3d56770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate hash\n",
    "def generate_hash(row):\n",
    "    hash_obj = hashlib.sha256()\n",
    "    concatenated_details = ''.join(str(row[col]) for col in row.index if col != 'last_updated')\n",
    "    hash_obj.update(concatenated_details.encode('utf-8'))\n",
    "    return hash_obj.hexdigest()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de30789c-8e46-4f68-8604-1495f43d12a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply hashes\n",
    "def apply_hashes(df):\n",
    "    df['data_hash'] = df.apply(generate_hash, axis=1)\n",
    "    df['last_updated'] = pd.to_datetime(datetime.now())\n",
    "    return df\n",
    "\n",
    "# def apply_hashes(df):\n",
    "#     def generate_hash(row):\n",
    "#         hash_obj = hashlib.sha256()\n",
    "#         concatenated_details = ''.join(str(row[col]) for col in sorted(row.index) if col != 'last_updated')\n",
    "#         hash_obj.update(concatenated_details.encode('utf-8'))\n",
    "#         return hash_obj.hexdigest()\n",
    "    \n",
    "#     df['data_hash'] = df.apply(generate_hash, axis=1)\n",
    "#     df['last_updated'] = pd.to_datetime(datetime.now())\n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef28824c-e7d4-40eb-bb93-baef6986ec73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect changes\n",
    "# def detect_changes(previous_df, current_df):\n",
    "#     combined_df = pd.merge(previous_df, current_df, on='hotel_id', suffixes=('_prev', '_curr'))\n",
    "#     changes = combined_df[(combined_df['data_hash_prev'] != combined_df['data_superseded']) | (combined_df['last_updated_prev'] < combined_df['last_updated_curr'])]\n",
    "#     return changes\n",
    "\n",
    "\n",
    "\n",
    "# def detect_changes(previous_df, current_df):\n",
    "#     combined_df = pd.merge(previous_df, current_df, on='hotel_id', how='outer', suffixes=('_prev', '_curr'))\n",
    "#     changes = combined_df[(combined_df['data_hash_prev'] != combined_df['data_hash_curr']) | \n",
    "#                           (combined_df['last_updated_prev'] < combined_df['last_inputd_curr'])]\n",
    "#     return changes\n",
    "\n",
    "# Function to detect changes and update\n",
    "def detect_changes(previous_df, current_df):\n",
    "    if not previous_df.empty:\n",
    "        combined_df = pd.merge(previous_df, current_df, on='hotel_id', how='outer', indicator=True)\n",
    "        changes_df = combined_df[combined_df['_merge'] != 'both']\n",
    "        return changes_df\n",
    "    return current_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa0104e-9879-4826-a4a2-859a02970482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_changes(df, filepath):\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"Data saved to {filepath}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2e4f7f-279f-4846-ad29-5af3925e344c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# parameters\n",
    "input_path = \"../Master Datasets/raw/hotel_detail_dataset_csv.csv\"\n",
    "output_path = \"../Master Datasets/Hashed and etc/hashed_timestamped_hotel_details.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcf80f7-5781-45e7-b4a6-9c755f800e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previously stored data or initialize it\n",
    "previous_df = load_data(output_path, input_template_path=input_path)\n",
    "\n",
    "# Load current data and apply hashes\n",
    "current_df = load_data(input_path)\n",
    "current_df = apply_hashes(current_df)\n",
    "\n",
    "# Detect changes\n",
    "changes_df = detect_changes(previous_df, current_df)\n",
    "\n",
    "# Save the changes if any\n",
    "# Save the changes if any\n",
    "if not changes_df.empty:\n",
    "    print(\"Changes detected, updating the dataset.\")\n",
    "    save_changes(changes_df, output_path)\n",
    "else:\n",
    "    print(\"No changes detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "038252a7-0bcb-4797-8225-034d1336027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'df1' in locals():\n",
    "#     del df1\n",
    "# if 'df2' in locals():\n",
    "#     del df2\n",
    "# if 'df' in locals():\n",
    "#     del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d658a82-0d85-4b50-9cfc-be89bc24b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# : Define the Hash Function\n",
    "\n",
    "# As discussed, youâ€™ll create a dynamic hash function that can adapt to changes in the data \n",
    "# structure, such as the addition of new columns. This function will hash all the relevant columns \n",
    "# except the last_updated column to avoid unnecessary updates due to timestamp changes alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6707281-a107-4247-a79b-555563b54c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the Hash Function to the DataFrame\n",
    "\n",
    "# apply this hash function to each row in your DataFrame to create a hash column. This column will \n",
    "# represent the current state of each row based on its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1968155-9fdc-4424-885a-0737d9dd4f5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "toc": {
   "base_numbering": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
