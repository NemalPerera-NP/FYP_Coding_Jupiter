{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78ed84d3-77f3-4ab4-804f-e7fecb6fbe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import papermill as pm\n",
    "from datetime import datetime\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23f070b0-1ec0-41ab-a019-26c20d463139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'path_to_your_excel_file.xlsx' with the path to your Excel file\n",
    "excel_file_1 = '../Master Datasets/raw/hotel_detail_dataset.xlsx'\n",
    "excel_file_2 = '../Master Datasets/raw/hotel_review.xlsx'\n",
    "\n",
    "# Read the Excel file\n",
    "df1 = pd.read_excel(excel_file_1)\n",
    "df2 = pd.read_excel(excel_file_2)\n",
    "\n",
    "# Convert to CSV\n",
    "df1.to_csv('../Master Datasets/raw/hotel_detail_dataset_csv.csv', index=False)\n",
    "df2.to_csv('../Master Datasets/raw/hotel_review_csv.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aeb0834-5fc6-47d2-827f-138094a69fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f07cc6bddbe4168afdc75ca4484994b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/15 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'code',\n",
       "   'execution_count': 1,\n",
       "   'id': 'abc6a885-3727-47a3-8366-c189e76cd5d3',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-05-26T15:40:54.511842',\n",
       "     'end_time': '2024-05-26T15:40:54.534322',\n",
       "     'duration': 0.02248,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-05-26T15:40:54.522918Z',\n",
       "     'iopub.execute_input': '2024-05-26T15:40:54.523913Z',\n",
       "     'shell.execute_reply': '2024-05-26T15:40:54.530929Z',\n",
       "     'iopub.status.idle': '2024-05-26T15:40:54.532273Z'}},\n",
       "   'outputs': [],\n",
       "   'source': '# this NoteBook is for update detection for the Hotel Details Dataset using Jupyter Notebooks'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'id': 'b148418c-fb74-4689-9d75-a2e5736c5fff',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-05-26T15:40:54.540603',\n",
       "     'end_time': '2024-05-26T15:40:54.544608',\n",
       "     'duration': 0.004005,\n",
       "     'status': 'completed'}},\n",
       "   'outputs': [],\n",
       "   'source': ''},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 2,\n",
       "   'id': 'b34a2624-e0f6-4e22-af50-dcb67430c3bc',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-05-26T15:40:54.547604',\n",
       "     'end_time': '2024-05-26T15:40:55.007581',\n",
       "     'duration': 0.459977,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-05-26T15:40:54.552602Z',\n",
       "     'iopub.execute_input': '2024-05-26T15:40:54.552602Z',\n",
       "     'shell.execute_reply': '2024-05-26T15:40:55.005542Z',\n",
       "     'iopub.status.idle': '2024-05-26T15:40:55.005542Z'}},\n",
       "   'outputs': [],\n",
       "   'source': '# Import necessary libraries\\nimport pandas as pd\\nimport hashlib\\nfrom datetime import datetime'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 3,\n",
       "   'id': '2aa13f17-bb80-492a-97e0-824868c11fbd',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-05-26T15:40:55.011552',\n",
       "     'end_time': '2024-05-26T15:40:55.022881',\n",
       "     'duration': 0.011329,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-05-26T15:40:55.015551Z',\n",
       "     'iopub.execute_input': '2024-05-26T15:40:55.015551Z',\n",
       "     'shell.execute_reply': '2024-05-26T15:40:55.020869Z',\n",
       "     'iopub.status.idle': '2024-05-26T15:40:55.020869Z'}},\n",
       "   'outputs': [],\n",
       "   'source': '\\n\\n# def load_data(filepath, input_template_path=None):\\n#     try:\\n#         # Try loading the existing data\\n#         df = pd.read_csv(filepath, parse_dates=[\\'last_updated\\'])\\n#     except FileNotFoundError:\\n#         print(f\"No file found at {filepath}. Initializing an empty DataFrame based on the template path.\")\\n#         # If no file is found and a template path is provided, create a DataFrame with the same structure\\n#         if input_template_path:\\n#             # Load only headers from the input template\\n#             temp_df = pd.read_csv(input_template_path, nrows=0)\\n#             columns = temp_df.columns.tolist()  # Get all column names from the input dataset\\n#         else:\\n#             # Fallback to a default set of columns if no input template path is provided\\n#             columns = [\\'hotel_id\\', \\'name\\', \\'location\\', \\'description\\']  # Default columns if no template is available\\n\\n#         # Initialize an empty DataFrame with the structure derived from the input dataset\\n#         df = pd.DataFrame(columns=columns)\\n#         df[\\'last_updated\\'] = pd.to_datetime(datetime.now())  # Ensure this column is added and set to now\\n#         df[\\'data_hash\\'] = pd.NA  # Initialize data_hash as missing\\n        \\n#     return df\\n\\ndef load_data(filepath, input_template_path=None):\\n    try:\\n        df = pd.read_csv(filepath)\\n        if \\'last_updated\\' in df.columns:\\n            df[\\'last_updated\\'] = pd.to_datetime(df[\\'last_updated\\'])\\n        else:\\n            df[\\'last_updated\\'] = pd.to_datetime(datetime.now())\\n    except FileNotFoundError:\\n        print(f\"No file found at {filepath}. Initializing based on the input template.\")\\n        if input_template_path:\\n            temp_df = pd.read_csv(input_template_path, nrows=0)\\n            df = pd.DataFrame(columns=temp_df.columns)\\n        else:\\n            df = pd.DataFrame(columns=[\\'hotel_id\\', \\'name\\', \\'location\\', \\'description\\'])\\n        df[\\'last_updated\\'] = pd.to_datetime(datetime.now())\\n        df[\\'data_hash\\'] = pd.NA\\n    return df'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 4,\n",
       "   'id': '689eee81-04e1-4bfc-a0fb-6ebda3d56770',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-05-26T15:40:55.025928',\n",
       "     'end_time': '2024-05-26T15:40:55.033616',\n",
       "     'duration': 0.007688,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-05-26T15:40:55.028948Z',\n",
       "     'iopub.execute_input': '2024-05-26T15:40:55.028948Z',\n",
       "     'shell.execute_reply': '2024-05-26T15:40:55.032361Z',\n",
       "     'iopub.status.idle': '2024-05-26T15:40:55.032577Z'}},\n",
       "   'outputs': [],\n",
       "   'source': \"# Function to generate hash\\ndef generate_hash(row):\\n    hash_obj = hashlib.sha256()\\n    concatenated_details = ''.join(str(row[col]) for col in row.index if col != 'last_updated')\\n    hash_obj.update(concatenated_details.encode('utf-8'))\\n    return hash_obj.hexdigest()\\n\"},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 5,\n",
       "   'id': 'de30789c-8e46-4f68-8604-1495f43d12a4',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-05-26T15:40:55.037600',\n",
       "     'end_time': '2024-05-26T15:40:55.046366',\n",
       "     'duration': 0.008766,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-05-26T15:40:55.040642Z',\n",
       "     'iopub.execute_input': '2024-05-26T15:40:55.040642Z',\n",
       "     'shell.execute_reply': '2024-05-26T15:40:55.044820Z',\n",
       "     'iopub.status.idle': '2024-05-26T15:40:55.045326Z'}},\n",
       "   'outputs': [],\n",
       "   'source': \"# Function to apply hashes\\ndef apply_hashes(df):\\n    df['data_hash'] = df.apply(generate_hash, axis=1)\\n    df['last_updated'] = pd.to_datetime(datetime.now())\\n    return df\\n\\n# def apply_hashes(df):\\n#     def generate_hash(row):\\n#         hash_obj = hashlib.sha256()\\n#         concatenated_details = ''.join(str(row[col]) for col in sorted(row.index) if col != 'last_updated')\\n#         hash_obj.update(concatenated_details.encode('utf-8'))\\n#         return hash_obj.hexdigest()\\n    \\n#     df['data_hash'] = df.apply(generate_hash, axis=1)\\n#     df['last_updated'] = pd.to_datetime(datetime.now())\\n#     return df\\n\"},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 6,\n",
       "   'id': 'ef28824c-e7d4-40eb-bb93-baef6986ec73',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-05-26T15:40:55.049337',\n",
       "     'end_time': '2024-05-26T15:40:55.058775',\n",
       "     'duration': 0.009438,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-05-26T15:40:55.053255Z',\n",
       "     'iopub.execute_input': '2024-05-26T15:40:55.053255Z',\n",
       "     'shell.execute_reply': '2024-05-26T15:40:55.056656Z',\n",
       "     'iopub.status.idle': '2024-05-26T15:40:55.056656Z'}},\n",
       "   'outputs': [],\n",
       "   'source': \"# Function to detect changes\\n# def detect_changes(previous_df, current_df):\\n#     combined_df = pd.merge(previous_df, current_df, on='hotel_id', suffixes=('_prev', '_curr'))\\n#     changes = combined_df[(combined_df['data_hash_prev'] != combined_df['data_superseded']) | (combined_df['last_updated_prev'] < combined_df['last_updated_curr'])]\\n#     return changes\\n\\n\\n\\n# def detect_changes(previous_df, current_df):\\n#     combined_df = pd.merge(previous_df, current_df, on='hotel_id', how='outer', suffixes=('_prev', '_curr'))\\n#     changes = combined_df[(combined_df['data_hash_prev'] != combined_df['data_hash_curr']) | \\n#                           (combined_df['last_updated_prev'] < combined_df['last_inputd_curr'])]\\n#     return changes\\n\\n# Function to detect changes and update\\ndef detect_changes(previous_df, current_df):\\n    if not previous_df.empty:\\n        combined_df = pd.merge(previous_df, current_df, on='hotel_id', how='outer', indicator=True)\\n        changes_df = combined_df[combined_df['_merge'] != 'both']\\n        return changes_df\\n    return current_df\"},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 7,\n",
       "   'id': '1fa0104e-9879-4826-a4a2-859a02970482',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-05-26T15:40:55.060779',\n",
       "     'end_time': '2024-05-26T15:40:55.069874',\n",
       "     'duration': 0.009095,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-05-26T15:40:55.064818Z',\n",
       "     'iopub.execute_input': '2024-05-26T15:40:55.064818Z',\n",
       "     'shell.execute_reply': '2024-05-26T15:40:55.067867Z',\n",
       "     'iopub.status.idle': '2024-05-26T15:40:55.067867Z'}},\n",
       "   'outputs': [],\n",
       "   'source': 'def save_changes(df, filepath):\\n    df.to_csv(filepath, index=False)\\n    print(f\"Data saved to {filepath}.\")'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 8,\n",
       "   'id': '0d2e4f7f-279f-4846-ad29-5af3925e344c',\n",
       "   'metadata': {'editable': True,\n",
       "    'slideshow': {'slide_type': ''},\n",
       "    'tags': ['parameters'],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-05-26T15:40:55.073220',\n",
       "     'end_time': '2024-05-26T15:40:55.081756',\n",
       "     'duration': 0.008536,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-05-26T15:40:55.076226Z',\n",
       "     'iopub.execute_input': '2024-05-26T15:40:55.076226Z',\n",
       "     'shell.execute_reply': '2024-05-26T15:40:55.079748Z',\n",
       "     'iopub.status.idle': '2024-05-26T15:40:55.079748Z'}},\n",
       "   'outputs': [],\n",
       "   'source': '# parameters\\ninput_path = \"../Master Datasets/raw/hotel_detail_dataset_csv.csv\"\\noutput_path = \"../Master Datasets/Hashed and etc/hashed_timestamped_hotel_details.csv\"'},\n",
       "  {'id': 'ccd8aa1b',\n",
       "   'cell_type': 'code',\n",
       "   'metadata': {'tags': ['injected-parameters'],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-05-26T15:40:55.084760',\n",
       "     'end_time': '2024-05-26T15:40:55.093078',\n",
       "     'duration': 0.008318,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-05-26T15:40:55.088753Z',\n",
       "     'iopub.execute_input': '2024-05-26T15:40:55.088753Z',\n",
       "     'shell.execute_reply': '2024-05-26T15:40:55.091166Z',\n",
       "     'iopub.status.idle': '2024-05-26T15:40:55.092040Z'}},\n",
       "   'execution_count': 9,\n",
       "   'source': '# Parameters\\ninput_path = \"../Master Datasets/raw/hotel_detail_dataset_csv.csv\"\\noutput_path = \"../Master Datasets/Hashed and etc/hashed_timestamped_hotel_details.csv\"\\n',\n",
       "   'outputs': []},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 10,\n",
       "   'id': '0bcf80f7-5781-45e7-b4a6-9c755f800e10',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-05-26T15:40:55.095078',\n",
       "     'end_time': '2024-05-26T15:40:55.412105',\n",
       "     'duration': 0.317027,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-05-26T15:40:55.099047Z',\n",
       "     'iopub.execute_input': '2024-05-26T15:40:55.099047Z',\n",
       "     'shell.execute_reply': '2024-05-26T15:40:55.410075Z',\n",
       "     'iopub.status.idle': '2024-05-26T15:40:55.410075Z'}},\n",
       "   'outputs': [{'output_type': 'stream',\n",
       "     'name': 'stdout',\n",
       "     'text': 'No file found at ../Master Datasets/Hashed and etc/hashed_timestamped_hotel_details.csv. Initializing based on the input template.\\nChanges detected, updating the dataset.\\n'},\n",
       "    {'output_type': 'stream',\n",
       "     'name': 'stdout',\n",
       "     'text': 'Data saved to ../Master Datasets/Hashed and etc/hashed_timestamped_hotel_details.csv.\\n'}],\n",
       "   'source': '# Load previously stored data or initialize it\\nprevious_df = load_data(output_path, input_template_path=input_path)\\n\\n# Load current data and apply hashes\\ncurrent_df = load_data(input_path)\\ncurrent_df = apply_hashes(current_df)\\n\\n# Detect changes\\nchanges_df = detect_changes(previous_df, current_df)\\n\\n# Save the changes if any\\n# Save the changes if any\\nif not changes_df.empty:\\n    print(\"Changes detected, updating the dataset.\")\\n    save_changes(changes_df, output_path)\\nelse:\\n    print(\"No changes detected.\")'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 11,\n",
       "   'id': '038252a7-0bcb-4797-8225-034d1336027a',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-05-26T15:40:55.415106',\n",
       "     'end_time': '2024-05-26T15:40:55.425638',\n",
       "     'duration': 0.010532,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-05-26T15:40:55.420103Z',\n",
       "     'iopub.execute_input': '2024-05-26T15:40:55.421085Z',\n",
       "     'iopub.status.idle': '2024-05-26T15:40:55.423602Z',\n",
       "     'shell.execute_reply': '2024-05-26T15:40:55.423602Z'}},\n",
       "   'outputs': [],\n",
       "   'source': \"# if 'df1' in locals():\\n#     del df1\\n# if 'df2' in locals():\\n#     del df2\\n# if 'df' in locals():\\n#     del df\"},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 12,\n",
       "   'id': '2d658a82-0d85-4b50-9cfc-be89bc24b144',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-05-26T15:40:55.429597',\n",
       "     'end_time': '2024-05-26T15:40:55.437672',\n",
       "     'duration': 0.008075,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-05-26T15:40:55.433599Z',\n",
       "     'iopub.execute_input': '2024-05-26T15:40:55.433599Z',\n",
       "     'iopub.status.idle': '2024-05-26T15:40:55.436634Z',\n",
       "     'shell.execute_reply': '2024-05-26T15:40:55.436634Z'}},\n",
       "   'outputs': [],\n",
       "   'source': '# : Define the Hash Function\\n\\n# As discussed, youâ€™ll create a dynamic hash function that can adapt to changes in the data \\n# structure, such as the addition of new columns. This function will hash all the relevant columns \\n# except the last_updated column to avoid unnecessary updates due to timestamp changes alone.'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': 13,\n",
       "   'id': 'b6707281-a107-4247-a79b-555563b54c32',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-05-26T15:40:55.441705',\n",
       "     'end_time': '2024-05-26T15:40:55.449013',\n",
       "     'duration': 0.007308,\n",
       "     'status': 'completed'},\n",
       "    'execution': {'iopub.status.busy': '2024-05-26T15:40:55.445641Z',\n",
       "     'iopub.execute_input': '2024-05-26T15:40:55.445641Z',\n",
       "     'iopub.status.idle': '2024-05-26T15:40:55.447974Z',\n",
       "     'shell.execute_reply': '2024-05-26T15:40:55.447974Z'}},\n",
       "   'outputs': [],\n",
       "   'source': '# Apply the Hash Function to the DataFrame\\n\\n# apply this hash function to each row in your DataFrame to create a hash column. This column will \\n# represent the current state of each row based on its content.'},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'id': 'a1968155-9fdc-4424-885a-0737d9dd4f5a',\n",
       "   'metadata': {'tags': [],\n",
       "    'papermill': {'exception': False,\n",
       "     'start_time': '2024-05-26T15:40:55.452982',\n",
       "     'end_time': '2024-05-26T15:40:55.455982',\n",
       "     'duration': 0.003,\n",
       "     'status': 'completed'}},\n",
       "   'outputs': [],\n",
       "   'source': ''}],\n",
       " 'metadata': {'kernelspec': {'display_name': 'Python 3 (ipykernel)',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'},\n",
       "  'language_info': {'name': 'python',\n",
       "   'version': '3.12.3',\n",
       "   'mimetype': 'text/x-python',\n",
       "   'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "   'pygments_lexer': 'ipython3',\n",
       "   'nbconvert_exporter': 'python',\n",
       "   'file_extension': '.py'},\n",
       "  'toc': {'base_numbering': 0},\n",
       "  'papermill': {'default_parameters': {},\n",
       "   'parameters': {'input_path': '../Master Datasets/raw/hotel_detail_dataset_csv.csv',\n",
       "    'output_path': '../Master Datasets/Hashed and etc/hashed_timestamped_hotel_details.csv'},\n",
       "   'environment_variables': {},\n",
       "   'version': '2.6.0',\n",
       "   'input_path': 'Module01_Hotel_Details_Update_Detection.ipynb',\n",
       "   'output_path': 'Update_Detection_Output.ipynb',\n",
       "   'start_time': '2024-05-26T15:40:53.179583',\n",
       "   'end_time': '2024-05-26T15:40:55.701585',\n",
       "   'duration': 2.522002,\n",
       "   'exception': None}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 5}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Execute the update detection notebook\n",
    "\n",
    "import papermill as pm\n",
    "\n",
    "pm.execute_notebook(\n",
    "    'Module01_Hotel_Details_Update_Detection.ipynb',\n",
    "    'Update_Detection_Output.ipynb',\n",
    "    parameters={\n",
    "        'input_path': '../Master Datasets/raw/hotel_detail_dataset_csv.csv',\n",
    "        'output_path': '../Master Datasets/Hashed and etc/hashed_timestamped_hotel_details.csv'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Depending on the output from the above, decide which notebook to run next\n",
    "# Assume you have a function to decide if you need to run ontology development\n",
    "# need_ontology_update = check_for_ontology_update('Update_Detection_Output.ipynb')\n",
    "\n",
    "# if need_ontology_update:\n",
    "#     pm.execute_notebook(\n",
    "#         'Ontology_Development.ipynb',\n",
    "#         'Ontology_Development_Output.ipynb'\n",
    "#     )\n",
    "\n",
    "# # Similar execution can be set for Ontology Population\n",
    "# pm.execute_notebook(\n",
    "#     'Ontology_Population.ipynb',\n",
    "#     'Ontology_Population_Output.ipynb'\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca7be4ac-ad7b-4dda-abe3-108bf75fce3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 11:12:35,268 - INFO: Read last HWM: 2020-05-31 10:31:02.982062\n",
      "2024-05-31 11:12:36,688 - INFO: Loaded 320836 new reviews for processing.\n",
      "2024-05-31 11:12:40,712 - INFO: New reviews saved for preprocessing. Triggering preprocessing notebook.\n",
      "2024-05-31 11:12:40,713 - INFO: Input Notebook:  Module01_Review_Basic_Preprocessing.ipynb\n",
      "2024-05-31 11:12:40,714 - INFO: Output Notebook: Module01_Review_Basic_Preprocessing_Output.ipynb\n",
      "2024-05-31 11:12:40,715 - WARNING: Passed unknown parameter: data_path\n",
      "2024-05-31 11:12:40,717 - WARNING: Input notebook does not contain a cell with tag 'parameters'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672b54eac810416d8d2a4a2a0ff37ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/2 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 11:12:42,012 - INFO: Executing notebook with kernel: python3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-Water Mark updated to: 2024-05-31 10:31:02.982062\n"
     ]
    }
   ],
   "source": [
    "# Setup basic logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')\n",
    "\n",
    "# Function to read the High-Water Mark\n",
    "def get_last_hwm(hwm_path):\n",
    "    try:\n",
    "        with open(hwm_path, 'r') as file:\n",
    "            last_hwm = pd.to_datetime(file.read().strip())\n",
    "        logging.info(f\"Read last HWM: {last_hwm}\")\n",
    "    except FileNotFoundError:\n",
    "        last_hwm = pd.to_datetime('1900-01-01')  # If no HWM found, use a very early date\n",
    "        logging.warning(\"No HWM file found. Setting to default early date.\")\n",
    "    return last_hwm\n",
    "\n",
    "# Function to load new reviews based on the High-Water Mark\n",
    "def load_new_reviews(filepath, last_hwm):\n",
    "    df = pd.read_csv(filepath)\n",
    "    df['processed_timestamp'] = pd.to_datetime(df['processed_timestamp'])\n",
    "    new_reviews = df[df['processed_timestamp'] > last_hwm]\n",
    "    logging.info(f\"Loaded {len(new_reviews)} new reviews for processing.\")\n",
    "    return new_reviews\n",
    "\n",
    "# Function to update the High-Water Mark\n",
    "def update_hwm(new_hwm, hwm_path):\n",
    "    with open(hwm_path, 'w') as file:\n",
    "        file.write(str(new_hwm))\n",
    "    print(f\"High-Water Mark updated to: {new_hwm}\")\n",
    "\n",
    "\n",
    "# Define file paths\n",
    "input_path = '../Master Datasets/raw/hotel_review_csv.csv'  # Path to the raw master dataset\n",
    "hwm_path = '../Master Datasets/Hashed and etc/high_water_mark.txt'  # Path to store the High-Water Mark\n",
    "output_for_preprocessing = '../Master Datasets/Hashed and etc/new_reviews_to_process.csv'  # Where to save new data for preprocessing\n",
    "\n",
    "# Execution logic in the master notebook\n",
    "last_hwm = get_last_hwm(hwm_path)  # Corrected variable name\n",
    "new_reviews = load_new_reviews(input_path, last_hwm)\n",
    "\n",
    "if not new_reviews.empty:\n",
    "    new_hwm = new_reviews['processed_timestamp'].max()\n",
    "     # Ensure datetime conversion if not already done\n",
    "    new_hwm = pd.to_datetime(new_hwm)\n",
    "    new_reviews.to_csv(output_for_preprocessing, index=False)\n",
    "    logging.info(\"New reviews saved for preprocessing. Triggering preprocessing notebook.\")\n",
    "    # Trigger the preprocessing notebook\n",
    "    try:\n",
    "        pm.execute_notebook(\n",
    "            'Module01_Review_Basic_Preprocessing.ipynb',\n",
    "            'Module01_Review_Basic_Preprocessing_Output.ipynb',\n",
    "            parameters={'data_path': output_for_preprocessing}\n",
    "        )\n",
    "        update_hwm(new_hwm, hwm_path)\n",
    "    except Exception as e:\n",
    "        logging.error(\"Error during notebook execution: {}\".string(e))\n",
    "else:\n",
    "    logging.info(\"No new reviews found to process.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da049eb-132a-4f7c-85f6-d4ecd5a88d68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
