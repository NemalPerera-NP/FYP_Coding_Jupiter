{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bd4206b-74ff-450c-b45d-c17048316799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffbec7a9-cd06-4138-bdc8-a8f74c2d13f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup basic logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s: %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "314e9b5c-166a-4a74-ad49-5a64d2a74f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hotel_id(hotel_name):\n",
    "    \"\"\"Create a deterministic HotelID based on the hotel name.\"\"\"\n",
    "    if pd.isna(hotel_name):\n",
    "        return np.nan\n",
    "    initials = ''.join([word[0] for word in hotel_name.split() if word]).upper()\n",
    "    name_length = len(hotel_name.replace(' ', ''))\n",
    "    return f\"{initials}{name_length}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfd665e3-296f-4c36-8d27-c09608ef7bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove HTML tags from text\n",
    "def remove_html_tags(text):\n",
    "    \"\"\"Remove HTML tags from text using BeautifulSoup.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    return BeautifulSoup(text, \"html.parser\").get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "759c6767-bd55-4e96-8d09-dd7e0d6e7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove URLs and emails from text\n",
    "def remove_urls_and_emails(text):\n",
    "    \"\"\"Remove URLs and email addresses from text.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return text\n",
    "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)  # Remove URLs\n",
    "    return re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za.]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '', text)  # Remove emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98c95ea4-c5c1-4075-a83c-fc27a9f55220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply normalization functions\n",
    "# The following function should be called to normalize text to lowercase.\n",
    "def normalize_text(dataframe):\n",
    "    \"\"\"Convert all text columns to lowercase.\"\"\"\n",
    "    text_columns = dataframe.select_dtypes(include=['object']).columns\n",
    "    for column in text_columns:\n",
    "        dataframe[column] = dataframe[column].apply(lambda x: x.lower() if pd.notna(x) else x)\n",
    "    print(\"Capitalization has been normalized across all text columns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e4995ae-551e-4c9d-b5a8-074214e8bf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_non_english(text):\n",
    "    \"\"\"Check if the majority of the text characters are non-ASCII.\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return False\n",
    "    return sum((ord(char) > 128 for char in text)) > 0.5 * len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1353cd90-fde3-45de-ac2f-66a48eeeb515",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def replace_non_english_reviews(dataframe):\n",
    "    \"\"\"Replace non-English reviews with their translated versions where applicable.\"\"\"\n",
    "    non_english_indices = dataframe.apply(lambda row: is_non_english(row['text']) and pd.notna(row['textTranslated']), axis=1)\n",
    "    dataframe.loc[non_english_indices, 'text'] = dataframe.loc[non_english_indices, 'textTranslated']\n",
    "    dataframe.loc[non_english_indices, 'textTranslated'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c371c23-a9ec-4d1b-af69-b3bca3420d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capitalization has been normalized across all text columns.\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "# This line reads a CSV file into a DataFrame. The correct method is `pd.read_csv`.\n",
    "hotel_review_dataset = pd.read_csv('../Master Datasets/Hashed and etc/new_reviews_to_process.csv')\n",
    "\n",
    "\n",
    "# Drop columns not needed for analysis\n",
    "# This code snippet drops specific columns from the DataFrame that are not required for further analysis.\n",
    "columns_to_drop = ['reviewerId', 'name', 'likesCount', 'reviewerNumberOfReviews', 'publishedAtDate', \n",
    "                   'reviewsDistribution/fiveStar', 'reviewsDistribution/threeStar', 'reviewsDistribution/oneStar', \n",
    "                   'totalScore','reviewsDistribution/twoStar','reviewsDistribution/fourStar']\n",
    "hotel_review_dataset.drop(columns=columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "# call for normalization functions\n",
    "normalize_text(hotel_review_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e1acac7-43fc-4727-85b2-f7630ec2e5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18768\\2679392284.py:6: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  return BeautifulSoup(text, \"html.parser\").get_text()\n",
      "2024-06-02 21:21:34,934 - INFO: Preprocessing completed and data saved to path_to_cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Apply the cleaning functions\n",
    "hotel_review_dataset['text'] = hotel_review_dataset['text'].apply(remove_html_tags).apply(remove_urls_and_emails)\n",
    "hotel_review_dataset['textTranslated'] = hotel_review_dataset['textTranslated'].apply(remove_html_tags).apply(remove_urls_and_emails)\n",
    "\n",
    "# Replace non-English reviews with translations\n",
    "replace_non_english_reviews(hotel_review_dataset)\n",
    "\n",
    "# Create HotelID(this should be called after combining the reviews into cells\n",
    "#hotel_review_dataset['HotelID'] = hotel_review_dataset['HotelName'].apply(create_hotel_id)\n",
    "\n",
    "# Save the cleaned and processed data\n",
    "hotel_review_dataset.to_csv('../Master Datasets/Reviews_data_processed.csv', index=False)\n",
    "\n",
    "logging.info(\"Preprocessing completed and data saved to path_to_cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bb487c-6408-4bc2-819a-8e3b746f734e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
